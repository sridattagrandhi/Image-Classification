{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791f6ed2-8be1-4268-a14c-e9778cc404cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "######################################\n",
    "# Reproducibility & Device Setup\n",
    "######################################\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "######################################\n",
    "# Offline Data Augmentation (Skip if Already Done)\n",
    "######################################\n",
    "original_train_dir = \"train/train\"\n",
    "augmented_train_dir = \"train_augmented\"\n",
    "\n",
    "if not os.path.exists(augmented_train_dir) or not os.listdir(augmented_train_dir):\n",
    "    os.makedirs(augmented_train_dir, exist_ok=True)\n",
    "    offline_aug_transforms = transforms.Compose([\n",
    "        transforms.Resize((288, 288)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0))\n",
    "    ])\n",
    "    num_augmented = 10\n",
    "    print(\"Starting offline data augmentation...\")\n",
    "    for class_name in os.listdir(original_train_dir):\n",
    "        class_path = os.path.join(original_train_dir, class_name)\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "        augmented_class_path = os.path.join(augmented_train_dir, class_name)\n",
    "        os.makedirs(augmented_class_path, exist_ok=True)\n",
    "        for img_name in os.listdir(class_path):\n",
    "            if not img_name.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "                continue\n",
    "            img_path = os.path.join(class_path, img_name)\n",
    "            try:\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening image {img_path}: {e}\")\n",
    "                continue\n",
    "            image.save(os.path.join(augmented_class_path, img_name))\n",
    "            for i in range(num_augmented):\n",
    "                aug_image = offline_aug_transforms(image)\n",
    "                new_filename = f\"{os.path.splitext(img_name)[0]}_aug{i}{os.path.splitext(img_name)[1]}\"\n",
    "                aug_image.save(os.path.join(augmented_class_path, new_filename))\n",
    "    print(\"Offline data augmentation complete. Augmented images saved in:\", augmented_train_dir)\n",
    "else:\n",
    "    print(\"Using existing augmented dataset in:\", augmented_train_dir)\n",
    "\n",
    "######################################\n",
    "# Online Transformations for Training & Validation\n",
    "# (Using only AutoAugment and removing GaussianBlur)\n",
    "######################################\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),  # Only AutoAugment is used\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3), value='random')\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "######################################\n",
    "# Custom Dataset (Avoiding datasets.ImageFolder)\n",
    "######################################\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        class_names = [d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))]\n",
    "        try:\n",
    "            sorted_class_names = sorted(class_names, key=lambda x: int(x))\n",
    "        except:\n",
    "            sorted_class_names = sorted(class_names)\n",
    "        self.class_to_idx = {class_name: i for i, class_name in enumerate(sorted_class_names)}\n",
    "        for class_name in sorted_class_names:\n",
    "            folder = os.path.join(root, class_name)\n",
    "            for fname in os.listdir(folder):\n",
    "                if fname.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    path = os.path.join(folder, fname)\n",
    "                    self.samples.append((path, self.class_to_idx[class_name]))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        path, label = self.samples[index]\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "######################################\n",
    "# Visual Transformer Model with Dropout\n",
    "# and Partial Freezing (Unfreeze last 4 layers + heads)\n",
    "######################################\n",
    "class ViT_Dropout(nn.Module):\n",
    "    def __init__(self, num_classes=100, dropout_p=0.5, freeze_feature_extractor=False):\n",
    "        super(ViT_Dropout, self).__init__()\n",
    "        self.model = models.vit_b_16(pretrained=True)\n",
    "        num_ftrs = self.model.heads.head.in_features\n",
    "        self.model.heads = nn.Sequential(\n",
    "            nn.Dropout(p=dropout_p),\n",
    "            nn.Linear(num_ftrs, num_classes)\n",
    "        )\n",
    "        if freeze_feature_extractor:\n",
    "            for name, param in self.model.named_parameters():\n",
    "                # Unfreeze layers 8, 9, 10, 11 and the classification head\n",
    "                if (\"encoder.layers.encoder_layer_8\" in name or\n",
    "                    \"encoder.layers.encoder_layer_9\" in name or\n",
    "                    \"encoder.layers.encoder_layer_10\" in name or\n",
    "                    \"encoder.layers.encoder_layer_11\" in name or\n",
    "                    \"heads\" in name):\n",
    "                    param.requires_grad = True\n",
    "                else:\n",
    "                    param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "######################################\n",
    "# MixUp Functions with adjusted alpha (0.2)\n",
    "######################################\n",
    "def mixup_data(x, y, alpha=0.2):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size).to(x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "######################################\n",
    "# Helper: Create Optimizer\n",
    "######################################\n",
    "def create_optimizer(model, config):\n",
    "    if config['freeze_feature_extractor']:\n",
    "        classifier_params = []\n",
    "        feature_params = []\n",
    "        for name, param in model.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if \"heads\" in name:\n",
    "                    classifier_params.append(param)\n",
    "                else:\n",
    "                    feature_params.append(param)\n",
    "        params = [\n",
    "            {'params': feature_params, 'lr': config['lr_feature']},\n",
    "            {'params': classifier_params, 'lr': config['lr_head']}\n",
    "        ]\n",
    "    else:\n",
    "        classifier_params = list(model.model.heads.parameters())\n",
    "        feature_params = [p for name, p in model.model.named_parameters() if \"heads\" not in name]\n",
    "        params = [\n",
    "            {'params': feature_params, 'lr': config['lr_feature']},\n",
    "            {'params': classifier_params, 'lr': config['lr_head']}\n",
    "        ]\n",
    "    \n",
    "    if config['optimizer_type'] == \"SGD\":\n",
    "        optimizer = optim.SGD(params, momentum=config.get('momentum', 0.9), weight_decay=config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.AdamW(params, weight_decay=config['weight_decay'])\n",
    "    return optimizer\n",
    "\n",
    "######################################\n",
    "# Training & Validation with Early Stopping\n",
    "######################################\n",
    "def train_validate(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs=5, patience=2):\n",
    "    best_val_acc = 0.0\n",
    "    best_model_state = None\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0.0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=0.2)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += lam * (preds == targets_a).sum().item() + (1 - lam) * (preds == targets_b).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        scheduler.step()\n",
    "        train_acc = correct / total\n",
    "        \n",
    "        model.eval()\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}/{num_epochs}\", leave=False):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_val += torch.sum(preds == labels.data).item()\n",
    "                total_val += labels.size(0)\n",
    "        val_acc = correct_val / total_val\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_state = model.state_dict()\n",
    "            epochs_no_improve = 0\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    return best_val_acc, best_model_state\n",
    "\n",
    "######################################\n",
    "# -- Using a Single Hyperparameter Set and Updated Freezing --\n",
    "######################################\n",
    "best_config = {\n",
    "    'optimizer_type': 'AdamW',\n",
    "    'lr_head': 1e-3,       # Updated learning rate\n",
    "    'lr_feature': 1e-3,    # Updated learning rate for feature extractor\n",
    "    'momentum': 0.0,       # Not used for AdamW\n",
    "    'weight_decay': 1e-4,\n",
    "    'freeze_feature_extractor': True\n",
    "}\n",
    "\n",
    "######################################\n",
    "# Final Training on Full Augmented Dataset\n",
    "######################################\n",
    "print(\"\\nUsing hyperparameters:\", best_config)\n",
    "final_train_dataset = CustomImageDataset(root=augmented_train_dir, transform=train_transforms)\n",
    "final_model = ViT_Dropout(\n",
    "    num_classes=100, \n",
    "    dropout_p=0.5,\n",
    "    freeze_feature_extractor=best_config['freeze_feature_extractor']\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = create_optimizer(final_model, best_config)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "num_epochs_final = 15  # Increased epochs\n",
    "patience_final = 5     # Increased patience\n",
    "\n",
    "print(\"\\nStarting final training on full augmented dataset...\")\n",
    "total_size = len(final_train_dataset)\n",
    "val_size = int(0.1 * total_size)\n",
    "train_size = total_size - val_size\n",
    "train_dataset_final, val_dataset_final = torch.utils.data.random_split(\n",
    "    final_train_dataset, [train_size, val_size], generator=torch.Generator().manual_seed(SEED)\n",
    ")\n",
    "train_dataset_final.dataset.transform = train_transforms\n",
    "val_dataset_final.dataset.transform = val_transforms\n",
    "\n",
    "final_train_loader = torch.utils.data.DataLoader(train_dataset_final, batch_size=64, shuffle=True, num_workers=4)\n",
    "final_val_loader = torch.utils.data.DataLoader(val_dataset_final, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "best_val_acc_final = 0.0\n",
    "best_final_model_state = None\n",
    "epochs_no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs_final):\n",
    "    final_model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(final_train_loader, desc=f\"Final Training Epoch {epoch+1}/{num_epochs_final}\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, alpha=0.2)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(inputs)\n",
    "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += lam * (preds == targets_a).sum().item() + (1 - lam) * (preds == targets_b).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    scheduler.step()\n",
    "    train_acc = correct / total\n",
    "\n",
    "    final_model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(final_val_loader, desc=f\"Final Validation Epoch {epoch+1}/{num_epochs_final}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = final_model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_val += torch.sum(preds == labels.data).item()\n",
    "            total_val += labels.size(0)\n",
    "    val_acc = correct_val / total_val\n",
    "    print(f\"Final Epoch {epoch+1} - Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    if val_acc > best_val_acc_final:\n",
    "        best_val_acc_final = val_acc\n",
    "        best_final_model_state = final_model.state_dict()\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience_final:\n",
    "            print(f\"Final training early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "final_model.load_state_dict(best_final_model_state)\n",
    "torch.save(final_model.state_dict(), \"transfer_learning_model_final.pth\")\n",
    "print(\"Final model saved as: transfer_learning_model_final.pth\")\n",
    "\n",
    "######################################\n",
    "# Test-Time Inference and Submission Generation\n",
    "######################################\n",
    "test_dir = \"test/test\"\n",
    "\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, test_dir, transform):\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted([f for f in os.listdir(test_dir) if f.lower().endswith('.jpg')])\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx]\n",
    "        img_path = os.path.join(self.test_dir, image_file)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, image_file\n",
    "\n",
    "test_dataset = TestDataset(test_dir, val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)\n",
    "\n",
    "final_model.eval()\n",
    "predictions = {}\n",
    "with torch.no_grad():\n",
    "    for inputs, image_files in tqdm(test_loader, desc=\"Predicting on Test Set\"):\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = final_model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for file, pred in zip(image_files, preds.cpu().numpy()):\n",
    "            predictions[file] = int(pred)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    \"ID\": list(predictions.keys()),\n",
    "    \"Label\": list(predictions.values())\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission = pd.read_csv(\"submission.csv\")\n",
    "submission[\"numeric_id\"] = submission[\"ID\"].apply(lambda x: int(re.findall(r\"\\d+\", x)[0]))\n",
    "submission_sorted = submission.sort_values(by=\"numeric_id\")\n",
    "submission_sorted.drop(columns=[\"numeric_id\"], inplace=True)\n",
    "submission_sorted.to_csv(\"submission_sorted.csv\", index=False)\n",
    "print(\"Submission file created: submission_sorted.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0e48c3-0a4f-4095-80cd-c594e5fd7010",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-17.m128",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-17:m128"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
